Previous work with Chat GPT on other measures 'ordered consistency' from the idea extending from the self similarity paper.
-- Good notation but probably need to table for now...
    https://chatgpt.com/c/6705b2a9-9358-8005-af2d-5df732fc9d8b


Previous work with Chat GPT On  A-QSR-RDMD metric code and notation...
-- Closer to what I have in the POC code (Spiral 1 code complete.)
    https://chatgpt.com/c/6706d189-62ec-8005-89dc-7b01db712aac

---- Maybe feed Chat GPT the latest code and ask for a precise but concise overview with notation?
-- Could get bloated if I give the code up front...

---- Maybe ask Chat GPT to describe the general framework for the investigation with the A-QSR-RDMD metric as one example to try within the investigation...
-- Trying in this chat...
Try to describe the general framework for the investigation where the A-QSR-RDMD metric is one example of a new measure to try within the investigation. Please ask if you need any additional information about the investigation to proceed with the task of precicesly but concisely describing the general framework of the investigation where the A-QSR-RDMD metric is just one example of a feature to implement in the experiment.
-- This worked out well and resulted in investigation_overview.tex
---- Maybe commit this initial version and then give Chat GPT the code to make it better aligned to the general intent and PoC implementation.

https://chatgpt.com/c/67180def-6c50-8005-a534-ce647647acd0
P1:
 The latex formatted document is attempting to describe the general framework for an investigation of embedding model performance. 
 Here, the A-QSR-RDMD metric is one example of a new measure of system wide text embedding quality assigned in this case to each query in an information retrieval data set. 
 The ideas incorporated into A-QSR-RDMD may also be partially represented in other new measures along with other ideas to try within the investigation. 
 We hope to identify new measures that will predict the retrieval performance of a search system, or search system component that relies on the analyzed text embedding model as a "Dense Retriever". 
 If we can predict "Dense Retriever" performance with a new measure, then we may also be able to improve the embedding model and search system with this knowledge. 
 To improve an embedding model with our conclusions, we would develop a new training scheme that incorporates the intuition, or data generated with the performance predicting measure such that it addresses some of the remaining error contributed by resolvable ambiguity in the embedding space identifable by the intuition / measure.
 We would expect to improve future embedding models for the task of acting as a "Dense Retriever" where the system error could be attributed to the ambiguity measured with our new metrics.
 After you have reviewed latex document, mark it up with comments to indicate where either the content or structure could be improved to better represent the general framework for this investigation. I will then provide the current python code which includes additional comments that should help resolve any comments about the details of our investigation.
 After I have provided all of the code, please ask if you need any additional information about the investigation to before we proceed with the task of precicesly but concisely describing the general framework of the investigation with a revised latex document.

**** Initial Latex Doc ****
P2: Great! Thank you for reviewing the initial LaTeX document and considering areas for improvement. I would like you to also consider the code and comments in the proof of concept code below before proceeding with a brief outline summarizing the key points for improvement which we will later incorporate into the LaTeX document. After I review the outline, I will provide any additional instructions along with the contents of one final python file prior to addressing the revisions. The final python script contains additional proof of concept code for calculating the retrieval performance for each query in the data set. The process of calculating retrieval performance will be repeated for each each text embedding model selected for the experiment once we move from proof of concept to the final execution phase of the investigation. 
**** #Investigation_MeasuresPoC.py ****

P3: Great! Thank you for those suggestions for improving the document and code.  Here are the contents of the final python for you to consider prior to addressing the revisions. As previously described, this python script contains additional proof of concept code for calculating the retrieval performance for each query in the data set. The process of calculating retrieval performance will be repeated for each each text embedding model selected for the experiment once we move from proof of concept to the final execution phase of the investigation. 

# Investigation_Retrieval_PerformancePoC.py

P4: Again, A-QSR-RDMD metric is just one example of a new set of measures for text embedding quality. These measures are assigned, in this case, to each query with an embedding generated by the text embedding model. These queries are sourced from an in an information retrieval data set.
 The ideas incorporated into A-QSR-RDMD may also be partially represented in other new measures along with other ideas to try within the investigation. 
 We hope to identify new measures that will predict the retrieval performance of a search system, or search system component that relies on the analyzed text embedding model as a "Dense Retriever". 
 If we can predict "Dense Retriever" performance with a new measure, then we may also be able to improve the embedding model and search system with this knowledge. 
 To improve an embedding model with our conclusions, we would develop a new training scheme that incorporates the intuition, or data generated with the performance predicting measure such that it addresses some of the remaining error contributed by resolvable ambiguity in the embedding space identifiable by the intuition / measure. 
 We would expect to improve future embedding models for the task of acting as a "Dense Retriever" where the system error could be attributed to the ambiguity measured with our new metrics.
 Please ask if you need any additional information about the investigation before we finalize our work to precisely but concisely describe the general framework of the investigation with a revised latex document. 
 Now revise the latex formatted document by improving the attempt at precisely and concisely describing the general framework for the investigation I have outlined for you with the original document, and the proof of concept code. Focus only on the Key Areas for Improvement you previously provided that address a presentation of the general framework for the investigation with specific examples where necessary to clarify. We will incorporate the remaining feedback into other work products to keep this original LaTeX document concise.


